{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d40ec0-f290-4ab9-8d7d-cb677fbb8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c10d07-1359-4019-a741-05ab37f2289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from files\n",
    "def load_data(directory):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        class_folder = os.path.join(directory, label)\n",
    "        if os.path.isdir(class_folder):\n",
    "            for fname in os.listdir(class_folder):\n",
    "                with open(os.path.join(class_folder, fname), 'r', encoding='utf-8') as file:\n",
    "                    texts.append(file.read())\n",
    "                    labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "# Load training and test data\n",
    "train_texts, train_labels = load_data('C:\\\\Users\\\\Moham\\\\Downloads\\\\57zpx667y9-2\\\\SANAD_SUBSET\\\\khaleej\\\\Train')\n",
    "test_texts, test_labels = load_data('C:\\\\Users\\\\Moham\\\\Downloads\\\\57zpx667y9-2\\\\SANAD_SUBSET\\\\khaleej\\\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63c9ca4-1d58-4f5a-9d3e-f66c1193a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880f7d80-cf16-4117-b39b-1a6e58cdfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 128\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9068cec7-19be-4cd9-94b8-fa43156ad1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c81c8f6-b48c-40ee-b51e-ae5d9b4668f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1280/1280 [==============================] - 6s 4ms/step - loss: 0.7344 - accuracy: 0.7993 - val_loss: 0.1964 - val_accuracy: 0.9510\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.1337 - accuracy: 0.9638 - val_loss: 0.1309 - val_accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0818 - accuracy: 0.9785 - val_loss: 0.1145 - val_accuracy: 0.9655\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0554 - accuracy: 0.9861 - val_loss: 0.1079 - val_accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0380 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9657\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9659\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.1202 - val_accuracy: 0.9646\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.1362 - val_accuracy: 0.9646\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.1375 - val_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.1507 - val_accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c99da8c650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc5899e-f607-433d-87e6-a1f0c31e900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9633\n",
      "Test Loss: 0.1507, Test Accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_padded, test_labels)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4186de27-759d-416f-87a4-c72b0f9f97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('C:\\\\Users\\\\Moham\\\\OneDrive\\\\Desktop\\\\OCR\\\\OCR_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa86a03-af22-4f21-b895-4d9b7da07892",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('C:\\\\Users\\\\Moham\\\\OneDrive\\\\Desktop\\\\OCR\\\\OCR_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f188462-39ec-4809-ac36-295d6233ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_file(file_path, tokenizer, model, max_length=128):\n",
    "    # Read the text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Tokenize and pad the text\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "    # Predict the class\n",
    "    prediction = model.predict(padded)\n",
    "    predicted_class = label_encoder.classes_[np.argmax(prediction)]\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010e68c2-dd98-495b-902b-9a3ae8d40a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "Predicted Class: Tech\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "file_path = 'C:\\\\Users\\\\Moham\\\\OneDrive\\\\Desktop\\\\OCR\\\\tech_stuff.txt'\n",
    "predicted_class = classify_text_file(file_path, tokenizer, model)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fa07a-6631-4dac-8c9a-528de1ac6c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
